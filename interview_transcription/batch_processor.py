#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç†è®¿è°ˆéŸ³é¢‘æ–‡ä»¶
å®Œæ•´æµç¨‹ï¼šMP3 â†’ è®¯é£è½¬å†™ â†’ åˆå¹¶æ®µè½ â†’ æ™ºè°±AIä¼˜åŒ– â†’ å‡è´«æªæ–½åˆ†æ
"""

import os
import json
import time
from pathlib import Path
from typing import List, Optional

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
# ç¡®ä¿èƒ½å¯¼å…¥Ifasr_llmæ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from text_cleaner import TextCleaner
from zhipu_cleaner import ZhipuTextCleaner
from poverty_reduction_analyzer import PovertyReductionAnalyzer

# å¯¼å…¥è®¯é£APIæ¨¡å—
from Ifasr_llm.Ifasr import XfyunAsrClient
from Ifasr_llm.orderResult import parse_order_result


class BatchProcessor:
    """æ‰¹é‡å¤„ç†è®¿è°ˆéŸ³é¢‘æ–‡ä»¶"""
    
    def __init__(self, 
                 input_dir: str,
                 output_base_dir: str = "output",
                 enable_ai: bool = True,
                 enable_poverty_analysis: bool = True):
        """
        åˆå§‹åŒ–æ‰¹å¤„ç†å™¨
        
        Args:
            input_dir: è¾“å…¥éŸ³é¢‘æ–‡ä»¶ç›®å½•
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            enable_ai: æ˜¯å¦å¯ç”¨æ™ºè°±AIä¼˜åŒ–
            enable_poverty_analysis: æ˜¯å¦å¯ç”¨å‡è´«æªæ–½åˆ†æ
        """
        self.input_dir = Path(input_dir)
        self.output_base_dir = Path(output_base_dir)
        self.enable_ai = enable_ai
        self.enable_poverty_analysis = enable_poverty_analysis
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self.api_dir = self.output_base_dir / "1_api_responses"
        self.merged_dir = self.output_base_dir / "2_merged_texts"
        self.ai_dir = self.output_base_dir / "3_ai_optimized"
        self.poverty_dir = self.output_base_dir / "4_poverty_reduction_summary"
        
        for dir_path in [self.api_dir, self.merged_dir, self.ai_dir, self.poverty_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–å·¥å…·
        self.text_cleaner = TextCleaner()
        
        if self.enable_ai:
            try:
                self.ai_cleaner = ZhipuTextCleaner()
                print("âœ… æ™ºè°±AIä¼˜åŒ–å·²åˆå§‹åŒ–")
            except Exception as e:
                print(f"âš ï¸  æ™ºè°±AIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_ai = False
        
        if self.enable_poverty_analysis:
            try:
                self.poverty_analyzer = PovertyReductionAnalyzer()
                print("âœ… å‡è´«æªæ–½åˆ†æå™¨å·²åˆå§‹åŒ–")
            except Exception as e:
                print(f"âš ï¸  å‡è´«æªæ–½åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_poverty_analysis = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'skipped': 0
        }
    
    def get_audio_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶"""
        audio_files = []
        for ext in ['.mp3', '.MP3', '.wav', '.WAV', '.m4a', '.M4A']:
            audio_files.extend(self.input_dir.glob(f"*{ext}"))
        
        # æŒ‰æ–‡ä»¶åæ’åº
        audio_files.sort(key=lambda x: x.name)
        return audio_files
    
    def process_single_file(self, audio_path: Path) -> bool:
        """
        å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        basename = audio_path.stem  # æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        print("\n" + "="*70)
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {audio_path.name}")
        print("="*70)
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
            api_file = self.api_dir / f"{basename}_api.json"
            merged_file = self.merged_dir / f"{basename}_merged.txt"
            ai_file = self.ai_dir / f"{basename}_ai.txt"
            poverty_file = self.poverty_dir / f"{basename}_poverty_summary.txt"
            
            # å¦‚æœæ‰€æœ‰è¾“å‡ºæ–‡ä»¶éƒ½å­˜åœ¨ï¼Œè·³è¿‡
            all_done = api_file.exists() and merged_file.exists()
            if self.enable_ai:
                all_done = all_done and ai_file.exists()
            if self.enable_poverty_analysis:
                all_done = all_done and poverty_file.exists()
            
            if all_done:
                print(f"â­ï¸  æ–‡ä»¶å·²å¤„ç†ï¼Œè·³è¿‡: {audio_path.name}")
                self.stats['skipped'] += 1
                return True
            
            # ========== æ­¥éª¤1: è®¯é£è¯­éŸ³è½¬å†™ ==========
            total_steps = 2 + (1 if self.enable_ai else 0) + (1 if self.enable_poverty_analysis else 0)
            print(f"\n[1/{total_steps}] ğŸ™ï¸  è®¯é£è¯­éŸ³è½¬å†™ä¸­...")
            
            asr_client = XfyunAsrClient(
                appid=Config.IFLYTEK_APPID,
                access_key_id=Config.IFLYTEK_API_KEY,
                access_key_secret=Config.IFLYTEK_API_SECRET,
                audio_file_path=str(audio_path)
            )
            
            # è·å–è½¬å†™ç»“æœ
            api_response = asr_client.get_transcribe_result()
            
            # ä¿å­˜APIåŸå§‹å“åº”
            with open(api_file, 'w', encoding='utf-8') as f:
                json.dump(api_response, f, ensure_ascii=False, indent=2)
            print(f"   âœ… APIå“åº”å·²ä¿å­˜: {api_file.name}")
            
            # è§£æè½¬å†™ç»“æœ
            transcript_text = parse_order_result(
                api_response, 
                with_speaker=True, 
                debug=False
            )
            
            if not transcript_text:
                raise Exception("è½¬å†™ç»“æœä¸ºç©º")
            
            # ========== æ­¥éª¤2: åˆå¹¶æ®µè½ ==========
            step_num = 2
            print(f"\n[{step_num}/{total_steps}] ğŸ“ åˆå¹¶è¿ç»­åŒä¸€è¯´è¯äººæ®µè½...")
            
            merged_text = self.text_cleaner.clean_transcript(
                transcript_text,
                merge_speakers=True,
                deep_clean=False,
                use_ai=False
            )
            
            # ä¿å­˜åˆå¹¶åçš„æ–‡æœ¬
            with open(merged_file, 'w', encoding='utf-8') as f:
                f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_path.name}\n")
                f.write(f"å¤„ç†æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*60 + "\n\n")
                f.write(merged_text)
            print(f"   âœ… åˆå¹¶æ–‡æœ¬å·²ä¿å­˜: {merged_file.name}")
            
            # ========== æ­¥éª¤3: æ™ºè°±AIä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰==========
            ai_text = None
            if self.enable_ai:
                step_num += 1
                print(f"\n[{step_num}/{total_steps}] ğŸ¤– æ™ºè°±AIæ™ºèƒ½ä¼˜åŒ–ä¸­...")
                
                # è§£æä¸ºå¯¹è¯åˆ—è¡¨
                dialogues = self.text_cleaner.parse_speaker_text(merged_text)
                
                # AIä¼˜åŒ–
                ai_dialogues = self.ai_cleaner.clean_dialogue_batch(
                    dialogues,
                    batch_size=5
                )
                
                # æ ¼å¼åŒ–è¾“å‡º
                ai_text = self.text_cleaner.format_to_text(
                    ai_dialogues,
                    show_speaker=True
                )
                
                # ä¿å­˜AIä¼˜åŒ–æ–‡æœ¬
                with open(ai_file, 'w', encoding='utf-8') as f:
                    f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_path.name}\n")
                    f.write(f"å¤„ç†æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("="*60 + "\n\n")
                    f.write(ai_text)
                print(f"   âœ… AIä¼˜åŒ–æ–‡æœ¬å·²ä¿å­˜: {ai_file.name}")
            
            # ========== æ­¥éª¤4: å‡è´«æªæ–½åˆ†æï¼ˆå¯é€‰ï¼‰==========
            if self.enable_poverty_analysis:
                step_num += 1
                print(f"\n[{step_num}/{total_steps}] ğŸ” åˆ†æå‡è´«æªæ–½ä¸­...")
                
                # ä½¿ç”¨AIä¼˜åŒ–åçš„æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨åˆå¹¶åçš„æ–‡æœ¬
                analysis_text = ai_text if ai_text else merged_text
                
                # æ‰§è¡Œåˆ†æ
                analysis_result = self.poverty_analyzer.analyze_interview(analysis_text)
                
                # ä¿å­˜åˆ†æç»“æœ
                self.poverty_analyzer.save_analysis(
                    analysis_result,
                    str(poverty_file),
                    audio_path.name
                )
            
            print(f"\nâœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {audio_path.name}")
            self.stats['success'] += 1
            return True
            
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {audio_path.name}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            self.stats['failed'] += 1
            return False
    
    def process_all(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶"""
        audio_files = self.get_audio_files()
        self.stats['total'] = len(audio_files)
        
        if self.stats['total'] == 0:
            print(f"\nâš ï¸  æœªåœ¨ {self.input_dir} ä¸­æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
        
        print("\n" + "="*70)
        print(f"ğŸ¯ æ‰¹é‡å¤„ç†ä»»åŠ¡")
        print("="*70)
        print(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_base_dir}")
        print(f"éŸ³é¢‘æ–‡ä»¶æ•°: {self.stats['total']}")
        print(f"å¯ç”¨AIä¼˜åŒ–: {'æ˜¯' if self.enable_ai else 'å¦'}")
        print(f"å¯ç”¨å‡è´«åˆ†æ: {'æ˜¯' if self.enable_poverty_analysis else 'å¦'}")
        print("="*70)
        
        # é€ä¸ªå¤„ç†
        for idx, audio_file in enumerate(audio_files, 1):
            print(f"\nè¿›åº¦: {idx}/{self.stats['total']}")
            self.process_single_file(audio_file)
            
            # é¿å…APIè¯·æ±‚è¿‡å¿«
            if idx < self.stats['total']:
                time.sleep(2)
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        self.print_summary()
    
    def print_summary(self):
        """æ‰“å°å¤„ç†ç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
        print("="*70)
        print(f"æ€»æ–‡ä»¶æ•°: {self.stats['total']}")
        print(f"æˆåŠŸå¤„ç†: {self.stats['success']} âœ…")
        print(f"å¤„ç†å¤±è´¥: {self.stats['failed']} âŒ")
        print(f"å·²è·³è¿‡: {self.stats['skipped']} â­ï¸")
        print("="*70)
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print(f"   APIå“åº”: {self.api_dir}")
        print(f"   åˆå¹¶æ–‡æœ¬: {self.merged_dir}")
        if self.enable_ai:
            print(f"   AIä¼˜åŒ–: {self.ai_dir}")
        if self.enable_poverty_analysis:
            print(f"   å‡è´«æªæ–½åˆ†æ: {self.poverty_dir}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡å¤„ç†è®¿è°ˆéŸ³é¢‘æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†mp3dataæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰éŸ³é¢‘
  python batch_processor.py -i mp3data
  
  # å¤„ç†å¹¶å¯ç”¨AIä¼˜åŒ–
  python batch_processor.py -i mp3data --ai
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python batch_processor.py -i mp3data -o my_output --ai
        """
    )
    
    parser.add_argument(
        '-i', '--input',
        type=str,
        required=True,
        help='è¾“å…¥éŸ³é¢‘æ–‡ä»¶ç›®å½•'
    )
    parser.add_argument(
        '-o', '--output',
        type=str,
        default='output',
        help='è¾“å‡ºåŸºç¡€ç›®å½•ï¼ˆé»˜è®¤: outputï¼‰'
    )
    parser.add_argument(
        '--ai',
        action='store_true',
        help='å¯ç”¨æ™ºè°±AIæ™ºèƒ½ä¼˜åŒ–'
    )
    parser.add_argument(
        '--no-ai',
        action='store_true',
        help='ç¦ç”¨æ™ºè°±AIä¼˜åŒ–ï¼ˆä»…è½¬å†™+åˆå¹¶ï¼‰'
    )
    parser.add_argument(
        '--poverty-analysis',
        action='store_true',
        default=True,
        help='å¯ç”¨å‡è´«æªæ–½åˆ†æï¼ˆé»˜è®¤å¯ç”¨ï¼‰'
    )
    parser.add_argument(
        '--no-poverty-analysis',
        action='store_true',
        help='ç¦ç”¨å‡è´«æªæ–½åˆ†æ'
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜¯å¦å¯ç”¨AI
    enable_ai = args.ai or not args.no_ai
    
    # ç¡®å®šæ˜¯å¦å¯ç”¨å‡è´«åˆ†æ
    enable_poverty_analysis = not args.no_poverty_analysis
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
    processor = BatchProcessor(
        input_dir=args.input,
        output_base_dir=args.output,
        enable_ai=enable_ai,
        enable_poverty_analysis=enable_poverty_analysis
    )
    
    try:
        processor.process_all()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        processor.print_summary()
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

