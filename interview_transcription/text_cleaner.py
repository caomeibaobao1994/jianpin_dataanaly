"""
æ–‡æœ¬æ¸…æ´—æ¨¡å—
æ·±åº¦æ¸…æ´—è®¿è°ˆæ–‡æœ¬ï¼šå»é™¤è¯­æ°”è¯ã€å£è¯­åŒ–è½¬ä¹¦é¢è¯­ã€å»é‡å¤ç­‰
"""

import re
from typing import List, Dict
from config import Config


class TextCleaner:
    """æ·±åº¦æ–‡æœ¬æ¸…æ´—å™¨"""
    
    def __init__(self):
        self.filler_words = Config.FILLER_WORDS
        self.colloquial_map = Config.COLLOQUIAL_TO_FORMAL
        self.repeat_threshold = Config.REPEAT_THRESHOLD
    
    def remove_filler_words(self, text: str) -> str:
        """
        å»é™¤è¯­æ°”è¯å’Œå¡«å……è¯ï¼ˆä¿ç•™æ ‡ç‚¹ç¬¦å·ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…æ´—åçš„æ–‡æœ¬
        """
        # æŒ‰é•¿åº¦é™åºæ’åºï¼Œé¿å…å…ˆæ›¿æ¢çŸ­çš„å½±å“é•¿çš„
        sorted_fillers = sorted(self.filler_words, key=len, reverse=True)
        
        for filler in sorted_fillers:
            escaped_filler = re.escape(filler)
            
            # 1. å¥é¦–çš„è¯­æ°”è¯ï¼ˆåé¢å¯èƒ½æœ‰æ ‡ç‚¹ï¼‰- ä¿ç•™æ ‡ç‚¹
            # "å•Šï¼Œä½ å¥½" â†’ "ï¼Œä½ å¥½"  "å—¯ã€‚" â†’ "ã€‚"
            text = re.sub(f'^{escaped_filler}([ï¼Œã€‚,.ï¼ï¼Ÿ!?]?)', r'\1', text)
            
            # 2. æ ‡ç‚¹åçš„è¯­æ°”è¯åé¢åˆè·Ÿæ ‡ç‚¹ - åˆå¹¶æ ‡ç‚¹ï¼ˆé¿å…é‡å¤æ ‡ç‚¹ï¼‰
            # "ä½ å¥½ï¼Œå•Šï¼Œæˆ‘æ˜¯" â†’ "ä½ å¥½ï¼Œæˆ‘æ˜¯"
            text = re.sub(f'([ï¼Œã€‚,.ï¼ï¼Ÿ!?]){escaped_filler}[ï¼Œã€‚,.ï¼ï¼Ÿ!?]', r'\1', text)
            
            # 3. è¯­æ°”è¯åæ¥æ ‡ç‚¹ï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰
            # "ä½ å¥½å•Šï¼Œæˆ‘æ˜¯" â†’ "ä½ å¥½ï¼Œæˆ‘æ˜¯"
            text = re.sub(f'{escaped_filler}([ï¼Œã€‚,.ï¼ï¼Ÿ!?])', r'\1', text)
            
            # 4. å­¤ç«‹çš„è¯­æ°”è¯ï¼ˆå‰åéƒ½ä¸æ˜¯æ ‡ç‚¹å’Œç©ºæ ¼ï¼‰
            # "ä½ å¥½å•Šæˆ‘æ˜¯" â†’ "ä½ å¥½æˆ‘æ˜¯"
            text = re.sub(f'(?<=[^ï¼Œã€‚,.ï¼ï¼Ÿ!?\s]){escaped_filler}(?=[^ï¼Œã€‚,.ï¼ï¼Ÿ!?\s])', '', text)
        
        return text
    
    def colloquial_to_formal(self, text: str) -> str:
        """
        å£è¯­åŒ–è¡¨è¾¾è½¬æ¢ä¸ºä¹¦é¢è¯­
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è½¬æ¢åçš„æ–‡æœ¬
        """
        # æŒ‰é•¿åº¦é™åºæ’åºï¼Œé¿å…å…ˆæ›¿æ¢çŸ­çš„å½±å“é•¿çš„
        sorted_items = sorted(self.colloquial_map.items(), key=lambda x: len(x[0]), reverse=True)
        
        for colloquial, formal in sorted_items:
            # ç›´æ¥æ›¿æ¢ï¼ˆä¸­æ–‡æ²¡æœ‰è¯è¾¹ç•Œçš„æ¦‚å¿µï¼‰
            text = text.replace(colloquial, formal)
        
        return text
    
    def remove_repeated_chars(self, text: str) -> str:
        """
        å»é™¤é‡å¤å­—ç¬¦
        ä¾‹å¦‚ï¼šå“ˆå“ˆå“ˆå“ˆ â†’ å“ˆå“ˆ
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å»é‡åçš„æ–‡æœ¬
        """
        # è¿ç»­é‡å¤3æ¬¡ä»¥ä¸Šçš„å­—ç¬¦å‡å°‘åˆ°2æ¬¡
        def replace_repeat(match):
            char = match.group(1)
            return char * 2
        
        text = re.sub(r'(.)\1{2,}', replace_repeat, text)
        return text
    
    def remove_repeated_phrases(self, text: str) -> str:
        """
        å»é™¤é‡å¤çŸ­è¯­
        ä¾‹å¦‚ï¼šæˆ‘è§‰å¾—æˆ‘è§‰å¾— â†’ æˆ‘è§‰å¾—
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å»é‡åçš„æ–‡æœ¬
        """
        # æ£€æµ‹2-10å­—çš„é‡å¤çŸ­è¯­
        for length in range(10, 1, -1):
            pattern = r'(.{' + str(length) + r'})\1+'
            text = re.sub(pattern, r'\1', text)
        
        return text
    
    def normalize_punctuation(self, text: str) -> str:
        """
        æ ‡ç‚¹ç¬¦å·è§„èŒƒåŒ–
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è§„èŒƒåŒ–åçš„æ–‡æœ¬
        """
        # å…¨è§’è½¬åŠè§’ï¼ˆè‹±æ–‡æ ‡ç‚¹ï¼‰
        text = text.replace('ï¼Œ', 'ï¼Œ')
        text = text.replace('ã€‚', 'ã€‚')
        text = text.replace('ï¼', 'ï¼')
        text = text.replace('ï¼Ÿ', 'ï¼Ÿ')
        text = text.replace('ï¼š', 'ï¼š')
        text = text.replace('ï¼›', 'ï¼›')
        
        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', '', text)
        
        # å»é™¤è¿ç»­æ ‡ç‚¹
        text = re.sub(r'[ï¼Œã€‚,.]([ï¼Œã€‚,.])+', 'ã€‚', text)
        text = re.sub(r'[ï¼!]+', 'ï¼', text)
        text = re.sub(r'[ï¼Ÿ?]+', 'ï¼Ÿ', text)
        
        # ç¡®ä¿å¥å­ä»¥æ ‡ç‚¹ç»“å°¾
        if text and text[-1] not in 'ã€‚ï¼ï¼Ÿ.!?':
            text += 'ã€‚'
        
        return text
    
    def remove_meaningless_segments(self, text: str) -> str:
        """
        å»é™¤æ— æ„ä¹‰ç‰‡æ®µ
        ä¾‹å¦‚ï¼šç¬‘å£°ã€åœé¡¿ç­‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…æ´—åçš„æ–‡æœ¬
        """
        meaningless = [
            'ç¬‘', 'å“ˆå“ˆ', 'å‘µå‘µ', 'å˜¿å˜¿',
            'å—¯å“¼', 'å””', 'å’¦', 'å’³å’³',
            'å˜¶', 'å“å‘€', 'å“å“Ÿ',
        ]
        
        for word in meaningless:
            # å•ç‹¬å‡ºç°æ‰åˆ é™¤
            text = re.sub(f'^{re.escape(word)}[ï¼Œã€‚,.]?', '', text)
            text = re.sub(f'[ï¼Œã€‚,.]{re.escape(word)}[ï¼Œã€‚,.]?', 'ï¼Œ', text)
        
        return text
    
    def clean_sentence(self, text: str) -> str:
        """
        æ¸…æ´—å•å¥æ–‡æœ¬ï¼ˆæ·±åº¦æ¸…æ´—ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…æ´—åçš„æ–‡æœ¬
        """
        # 1. å»é™¤è¯­æ°”è¯
        text = self.remove_filler_words(text)
        
        # 2. å»é™¤é‡å¤å­—ç¬¦
        text = self.remove_repeated_chars(text)
        
        # 3. å»é™¤é‡å¤çŸ­è¯­
        text = self.remove_repeated_phrases(text)
        
        # 4. å£è¯­åŒ–è½¬ä¹¦é¢è¯­
        text = self.colloquial_to_formal(text)
        
        # 5. å»é™¤æ— æ„ä¹‰ç‰‡æ®µ
        text = self.remove_meaningless_segments(text)
        
        # 6. æ ‡ç‚¹ç¬¦å·è§„èŒƒåŒ–
        text = self.normalize_punctuation(text)
        
        # 7. å»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()
        
        return text
    
    def clean_dialogues(self, dialogues: List[Dict]) -> List[Dict]:
        """
        æ¸…æ´—å¯¹è¯åˆ—è¡¨
        
        Args:
            dialogues: åŸå§‹å¯¹è¯åˆ—è¡¨ï¼Œæ ¼å¼ [{'speaker': 'Speaker 1', 'text': '...'}]
            
        Returns:
            æ¸…æ´—åçš„å¯¹è¯åˆ—è¡¨
        """
        cleaned = []
        
        for item in dialogues:
            speaker = item['speaker']
            text = item['text']
            
            # æ¸…æ´—æ–‡æœ¬
            cleaned_text = self.clean_sentence(text)
            
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            if cleaned_text:
                cleaned.append({
                    'speaker': speaker,
                    'text': cleaned_text
                })
        
        return cleaned
    
    def merge_same_speaker(self, dialogues: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶è¿ç»­çš„åŒä¸€è¯´è¯äººå¯¹è¯
        
        Args:
            dialogues: å¯¹è¯åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„å¯¹è¯åˆ—è¡¨
        """
        if not dialogues:
            return []
        
        merged = []
        current_speaker = dialogues[0]['speaker']
        current_text = dialogues[0]['text']
        
        for item in dialogues[1:]:
            if item['speaker'] == current_speaker:
                # åŒä¸€è¯´è¯äººï¼Œåˆå¹¶æ–‡æœ¬
                current_text += item['text']
            else:
                # ä¸åŒè¯´è¯äººï¼Œä¿å­˜ä¸Šä¸€æ®µ
                merged.append({
                    'speaker': current_speaker,
                    'text': current_text
                })
                current_speaker = item['speaker']
                current_text = item['text']
        
        # ä¿å­˜æœ€åä¸€æ®µ
        merged.append({
            'speaker': current_speaker,
            'text': current_text
        })
        
        return merged
    
    def parse_speaker_text(self, text: str) -> List[Dict]:
        """
        è§£æå¸¦è¯´è¯äººæ ‡è®°çš„æ–‡æœ¬ï¼Œè½¬æ¢ä¸ºå¯¹è¯åˆ—è¡¨
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        - ã€è®¿è°ˆè€…ã€‘æ–‡æœ¬å†…å®¹
        - è®¿è°ˆè€…ï¼šæ–‡æœ¬å†…å®¹
        
        Args:
            text: å¸¦è¯´è¯äººæ ‡è®°çš„æ–‡æœ¬å­—ç¬¦ä¸²
            
        Returns:
            å¯¹è¯åˆ—è¡¨ [{'speaker': 'è®¿è°ˆè€…', 'text': '...'}]
        """
        dialogues = []
        
        # åŒ¹é…ã€è¯´è¯äººã€‘æˆ–è¯´è¯äººï¼šæ ¼å¼
        # æ”¯æŒï¼šã€è®¿è°ˆè€…ã€‘æ–‡æœ¬ æˆ– è®¿è°ˆè€…ï¼šæ–‡æœ¬
        pattern = r'(?:ã€([^ã€‘]+)ã€‘|([^ï¼š\n]+)ï¼š)([^\nã€]+)'
        
        matches = re.finditer(pattern, text, re.MULTILINE)
        
        for match in matches:
            speaker = match.group(1) or match.group(2)  # ã€ã€‘å†…æˆ–ï¼šå‰çš„å†…å®¹
            content = match.group(3)  # æ–‡æœ¬å†…å®¹
            
            if speaker and content:
                speaker = speaker.strip()
                content = content.strip()
                
                if content:  # è¿‡æ»¤ç©ºæ–‡æœ¬
                    dialogues.append({
                        'speaker': speaker,
                        'text': content
                    })
        
        return dialogues
    
    def format_to_text(self, dialogues: List[Dict], 
                       show_speaker: bool = True,
                       speaker_labels: Dict[str, str] = None) -> str:
        """
        æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬
        
        Args:
            dialogues: å¯¹è¯åˆ—è¡¨
            show_speaker: æ˜¯å¦æ˜¾ç¤ºè¯´è¯äººæ ‡è®°
            speaker_labels: è¯´è¯äººæ ‡ç­¾æ˜ å°„ï¼Œå¦‚ {'Speaker 1': 'è®¿è°ˆè€…', 'Speaker 2': 'å—è®¿è€…'}
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        lines = []
        
        for item in dialogues:
            speaker = item['speaker']
            text = item['text']
            
            # åº”ç”¨è‡ªå®šä¹‰æ ‡ç­¾
            if speaker_labels and speaker in speaker_labels:
                speaker = speaker_labels[speaker]
            
            if show_speaker:
                lines.append(f"ã€{speaker}ã€‘{text}")
            else:
                lines.append(text)
        
        return '\n\n'.join(lines)
    
    def clean_transcript(self, text: str, merge_speakers: bool = True, 
                        deep_clean: bool = True, use_ai: bool = False,
                        ai_batch_size: int = 5) -> str:
        """
        æ¸…æ´—è½¬å†™æ–‡æœ¬ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
        
        å¤„ç†æµç¨‹ï¼š
        1. è§£æå¸¦è¯´è¯äººæ ‡è®°çš„æ–‡æœ¬
        2. åˆå¹¶è¿ç»­åŒä¸€è¯´è¯äººçš„æ®µè½ï¼ˆå¯é€‰ï¼‰
        3. æ·±åº¦æ–‡æœ¬æ¸…æ´—ï¼ˆå¯é€‰ï¼‰
        4. AIæ™ºèƒ½ä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œéœ€è¦æ™ºè°±AI APIï¼‰
        5. æ ¼å¼åŒ–è¾“å‡º
        
        Args:
            text: åŸå§‹è½¬å†™æ–‡æœ¬ï¼ˆå¸¦è¯´è¯äººæ ‡è®°ï¼‰
            merge_speakers: æ˜¯å¦åˆå¹¶è¿ç»­åŒä¸€è¯´è¯äºº
            deep_clean: æ˜¯å¦è¿›è¡Œè§„åˆ™æ·±åº¦æ¸…æ´—
            use_ai: æ˜¯å¦ä½¿ç”¨æ™ºè°±AIè¿›è¡Œæ™ºèƒ½ä¼˜åŒ–
            ai_batch_size: AIå¤„ç†æ—¶æ¯æ‰¹æ¬¡çš„æ®µè½æ•°
            
        Returns:
            æ¸…æ´—åçš„æ–‡æœ¬
        """
        # 1. è§£ææ–‡æœ¬
        dialogues = self.parse_speaker_text(text)
        
        if not dialogues:
            return text  # è§£æå¤±è´¥ï¼Œè¿”å›åŸæ–‡
        
        # 2. åˆå¹¶è¿ç»­åŒä¸€è¯´è¯äººï¼ˆå¦‚æœéœ€è¦ï¼‰
        if merge_speakers:
            dialogues = self.merge_same_speaker(dialogues)
        
        # 3. è§„åˆ™æ·±åº¦æ¸…æ´—ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if deep_clean:
            dialogues = self.clean_dialogues(dialogues)
        
        # 4. AIæ™ºèƒ½ä¼˜åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if use_ai:
            try:
                from zhipu_cleaner import ZhipuTextCleaner
                print("\nğŸ¤– å¯ç”¨æ™ºè°±AIæ™ºèƒ½ä¼˜åŒ–...")
                ai_cleaner = ZhipuTextCleaner()
                dialogues = ai_cleaner.clean_dialogue_batch(dialogues, batch_size=ai_batch_size)
            except ImportError as e:
                print(f"âš ï¸  æ— æ³•ä½¿ç”¨æ™ºè°±AI: {str(e)}")
                print("   è¯·å®‰è£…: pip install zhipuai")
            except Exception as e:
                print(f"âš ï¸  AIæ¸…æ´—å‡ºé”™: {str(e)}")
                print("   å°†ç»§ç»­ä½¿ç”¨è§„åˆ™æ¸…æ´—ç»“æœ")
        
        # 5. æ ¼å¼åŒ–è¾“å‡º
        return self.format_to_text(dialogues, show_speaker=True)

