# -*- coding: utf-8 -*-
"""
WhisperX API å°è£…
ä½¿ç”¨ WhisperX è¿›è¡Œè¯­éŸ³è½¬å†™å’Œè¯´è¯äººåˆ†ç¦»
å®˜æ–¹ä»“åº“: https://github.com/m-bain/whisperX
"""

import os
from pathlib import Path
from typing import Dict, Optional, List
import warnings
warnings.filterwarnings('ignore')


class WhisperXTranscriber:
    """WhisperX è¯­éŸ³è½¬å†™å®¢æˆ·ç«¯ï¼ˆæ”¯æŒè¯´è¯äººåˆ†ç¦»ï¼‰"""
    
    def __init__(self, 
                 model_size: str = "small",
                 device: str = "cpu",
                 compute_type: str = "int8",
                 hf_token: str = None):
        """
        åˆå§‹åŒ– WhisperX è½¬å†™å®¢æˆ·ç«¯
        
        Args:
            model_size: æ¨¡å‹å¤§å° (tiny/base/small/medium/large)
            device: è®¾å¤‡ (cpu/cuda)
            compute_type: è®¡ç®—ç²¾åº¦ (int8/float16/float32)
            hf_token: Hugging Face Tokenï¼ˆè¯´è¯äººåˆ†ç¦»éœ€è¦ï¼‰
        """
        self.model_size = model_size
        self.device = device
        self.compute_type = compute_type
        self.hf_token = hf_token
        
        self.model = None
        self.align_model = None
        self.diarize_model = None
        
        self._check_dependencies()
    
    def _check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
        try:
            import whisperx
            self.whisperx = whisperx
        except ImportError:
            raise ImportError(
                "WhisperX æœªå®‰è£…ã€‚è¯·è¿è¡Œ:\n"
                "pip3 install git+https://github.com/m-bain/whisperX.git"
            )
        
        try:
            import torch
        except ImportError:
            raise ImportError(
                "PyTorch æœªå®‰è£…ã€‚è¯·è¿è¡Œ:\n"
                "pip3 install torch"
            )
    
    def load_models(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model is None:
            print(f"ğŸ“¥ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {self.model_size}")
            print("   é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            self.model = self.whisperx.load_model(
                self.model_size,
                self.device,
                compute_type=self.compute_type,
                language="zh"
            )
            print("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_align_model(self, language_code="zh"):
        """åŠ è½½å¯¹é½æ¨¡å‹"""
        if self.align_model is None:
            print("ğŸ“¥ æ­£åœ¨åŠ è½½æ—¶é—´å¯¹é½æ¨¡å‹...")
            self.align_model, self.align_metadata = self.whisperx.load_align_model(
                language_code=language_code,
                device=self.device
            )
            print("âœ… å¯¹é½æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_diarize_model(self):
        """åŠ è½½è¯´è¯äººåˆ†ç¦»æ¨¡å‹"""
        if self.diarize_model is None:
            if not self.hf_token:
                raise ValueError(
                    "è¯´è¯äººåˆ†ç¦»éœ€è¦ Hugging Face Tokenã€‚\n"
                    "è¯·è®¿é—® https://huggingface.co/settings/tokens è·å–ã€‚"
                )
            
            print("ğŸ“¥ æ­£åœ¨åŠ è½½è¯´è¯äººåˆ†ç¦»æ¨¡å‹...")
            print("   é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            self.diarize_model = self.whisperx.DiarizationPipeline(
                use_auth_token=self.hf_token,
                device=self.device
            )
            print("âœ… è¯´è¯äººåˆ†ç¦»æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def transcribe_audio(self, audio_path: Path) -> Optional[Dict]:
        """
        è½¬å†™éŸ³é¢‘
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬å†™ç»“æœå­—å…¸
        """
        if not audio_path.exists():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
        
        # åŠ è½½éŸ³é¢‘
        print(f"ğŸ“„ æ­£åœ¨åŠ è½½éŸ³é¢‘: {audio_path.name}")
        audio = self.whisperx.load_audio(str(audio_path))
        
        # è½¬å†™
        print("ğŸ¤ æ­£åœ¨è¿›è¡Œè¯­éŸ³è½¬å†™...")
        result = self.model.transcribe(audio, batch_size=16)
        
        print(f"âœ… è½¬å†™å®Œæˆï¼Œå…±è¯†åˆ«å‡º {len(result['segments'])} ä¸ªç‰‡æ®µ")
        
        return result
    
    def align_timestamps(self, audio_path: Path, result: Dict) -> Dict:
        """
        ä¼˜åŒ–æ—¶é—´æˆ³å¯¹é½
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            result: è½¬å†™ç»“æœ
            
        Returns:
            å¯¹é½åçš„ç»“æœ
        """
        self.load_align_model()
        
        print("â±ï¸  æ­£åœ¨ä¼˜åŒ–æ—¶é—´æˆ³å¯¹é½...")
        audio = self.whisperx.load_audio(str(audio_path))
        
        result = self.whisperx.align(
            result["segments"],
            self.align_model,
            self.align_metadata,
            audio,
            self.device,
            return_char_alignments=False
        )
        
        print("âœ… æ—¶é—´æˆ³å¯¹é½å®Œæˆ")
        return result
    
    def diarize_speakers(self, audio_path: Path, min_speakers: int = 2, max_speakers: int = 2) -> Dict:
        """
        è¯´è¯äººåˆ†ç¦»
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            min_speakers: æœ€å°‘è¯´è¯äººæ•°
            max_speakers: æœ€å¤šè¯´è¯äººæ•°
            
        Returns:
            è¯´è¯äººåˆ†ç¦»ç»“æœ
        """
        self.load_diarize_model()
        
        print(f"ğŸ‘¥ æ­£åœ¨è¿›è¡Œè¯´è¯äººåˆ†ç¦»ï¼ˆ{min_speakers}-{max_speakers}äººï¼‰...")
        audio = self.whisperx.load_audio(str(audio_path))
        
        diarize_segments = self.diarize_model(
            audio,
            min_speakers=min_speakers,
            max_speakers=max_speakers
        )
        
        print("âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ")
        return diarize_segments
    
    def assign_speakers(self, result: Dict, diarize_segments: Dict) -> Dict:
        """
        å°†è¯´è¯äººæ ‡è®°åˆ†é…åˆ°è½¬å†™ç»“æœ
        
        Args:
            result: å¯¹é½åçš„è½¬å†™ç»“æœ
            diarize_segments: è¯´è¯äººåˆ†ç¦»ç»“æœ
            
        Returns:
            å¸¦è¯´è¯äººæ ‡è®°çš„ç»“æœ
        """
        print("ğŸ”— æ­£åœ¨åˆ†é…è¯´è¯äººæ ‡è®°...")
        result = self.whisperx.assign_word_speakers(diarize_segments, result)
        print("âœ… è¯´è¯äººæ ‡è®°åˆ†é…å®Œæˆ")
        return result
    
    def format_result(self, result: Dict) -> List[Dict]:
        """
        æ ¼å¼åŒ–ç»“æœä¸ºç»Ÿä¸€æ ¼å¼
        
        Args:
            result: WhisperX ç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯åˆ—è¡¨ [{'speaker': 'Speaker 1', 'text': '...'}]
        """
        dialogues = []
        
        for segment in result.get("segments", []):
            speaker = segment.get("speaker", "SPEAKER_00")
            text = segment.get("text", "").strip()
            
            if text:
                # è½¬æ¢è¯´è¯äººæ ‡è®°æ ¼å¼
                # SPEAKER_00 -> Speaker 1
                speaker_num = int(speaker.split("_")[-1]) + 1
                speaker_label = f"Speaker {speaker_num}"
                
                dialogues.append({
                    'speaker': speaker_label,
                    'text': text
                })
        
        return dialogues
    
    def transcribe(self, 
                   audio_path: Path,
                   enable_diarization: bool = True,
                   min_speakers: int = 2,
                   max_speakers: int = 2) -> Optional[List[Dict]]:
        """
        å®Œæ•´çš„è½¬å†™æµç¨‹ï¼ˆä¸€ç«™å¼æ–¹æ³•ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            enable_diarization: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»
            min_speakers: æœ€å°‘è¯´è¯äººæ•°
            max_speakers: æœ€å¤šè¯´è¯äººæ•°
            
        Returns:
            å¯¹è¯åˆ—è¡¨
        """
        print("\n" + "="*60)
        print("ğŸ™ï¸  WhisperX è¯­éŸ³è½¬å†™")
        print("="*60 + "\n")
        
        try:
            # 1. è½¬å†™éŸ³é¢‘
            result = self.transcribe_audio(audio_path)
            if not result:
                return None
            
            # 2. æ—¶é—´å¯¹é½
            result = self.align_timestamps(audio_path, result)
            
            # 3. è¯´è¯äººåˆ†ç¦»ï¼ˆå¯é€‰ï¼‰
            if enable_diarization:
                if not self.hf_token:
                    print("âš ï¸  æœªæä¾› HF_TOKENï¼Œè·³è¿‡è¯´è¯äººåˆ†ç¦»")
                    print("   æ‰€æœ‰æ–‡æœ¬å°†æ ‡è®°ä¸º 'Speaker 1'")
                else:
                    diarize_segments = self.diarize_speakers(
                        audio_path,
                        min_speakers,
                        max_speakers
                    )
                    result = self.assign_speakers(result, diarize_segments)
            
            # 4. æ ¼å¼åŒ–ç»“æœ
            dialogues = self.format_result(result)
            
            print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼å…±ç”Ÿæˆ {len(dialogues)} æ®µå¯¹è¯")
            return dialogues
            
        except Exception as e:
            print(f"\nâŒ è½¬å†™å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None


def test_whisperx():
    """æµ‹è¯• WhisperX åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ§ª WhisperX åŠŸèƒ½æµ‹è¯•")
    print("="*60 + "\n")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import whisperx
        print("âœ… WhisperX å·²å®‰è£…")
    except ImportError:
        print("âŒ WhisperX æœªå®‰è£…")
        print("\nå®‰è£…å‘½ä»¤:")
        print("  pip3 install git+https://github.com/m-bain/whisperX.git")
        return
    
    try:
        import torch
        print(f"âœ… PyTorch å·²å®‰è£… (ç‰ˆæœ¬: {torch.__version__})")
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
        print("\nå®‰è£…å‘½ä»¤:")
        print("  pip3 install torch")
        return
    
    # æ£€æŸ¥ HF Token
    hf_token = os.getenv('HF_TOKEN')
    if hf_token:
        print(f"âœ… HF_TOKEN å·²è®¾ç½®: {hf_token[:10]}...")
    else:
        print("âš ï¸  HF_TOKEN æœªè®¾ç½®ï¼ˆè¯´è¯äººåˆ†ç¦»éœ€è¦ï¼‰")
        print("   è·å–åœ°å€: https://huggingface.co/settings/tokens")
    
    print("\n" + "="*60)
    print("âœ… åŸºç¡€æ£€æŸ¥å®Œæˆ")
    print("="*60 + "\n")


if __name__ == '__main__':
    test_whisperx()

